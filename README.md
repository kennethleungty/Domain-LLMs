# Domain-Specific-LLMs
Customized Language Models for Specific Domains and Industries

___

[![Contributions Welcome!](https://img.shields.io/badge/Contributions-Welcome-brightgreen?style=for-the-badge)](./CONTRIBUTING.md)
<hr>

## Contents
1. [Finance](#finance)
2. [Healthcare](#healthcare)


___
<a name="finance"></a>
## Finance
| Name | Model Type | Description | Demo | Paper | Repo | Website |
| --- | --- | --- | --- | --- | --- | --- |
| BloombergGPT | Pre-trained | 50-billion parameter LLM trained on a wide range of financial data (363 billion token dataset) | - | [:link:](https://arxiv.org/abs/2303.17564) | - | - |
| FinGPT | Fine-tuned | Series of LLMs fine-tuned on base models (e.g., Llama-2) with open finance data | - | [:link:](https://arxiv.org/abs/2306.06031)  | [:link:](https://github.com/AI4Finance-Foundation/FinGPT) | [:link:](https://website.com) |
| FinMA | Fine-tuned | Financial LLM from fine-tuning LLaMa with finance-based instruction data with 136K data samples| [:link:](https://huggingface.co/ChanceFocus/finma-7b-nlp) | [:link:](https://arxiv.org/abs/2306.05443)  | [:link:](https://github.com/chancefocus/PIXIU) | - |


___
<a name="healthcare"></a>
## Healthcare
| Name | Model Type | Description | Repo | Paper | Demo |
| --- | --- | --- | --- | --- | --- |
| Med-PaLM | Fine-tuned | Google's LLM (fine-tuned using PaLM as base model) designed to provide high quality answers to medical questions. | - | [:link:](https://www.nature.com/articles/s41586-023-06291-2)  | - | [:link:](https://sites.research.google/med-palm/) |
| Med-PaLM 2 | Fine-tuned | Enhanced version of Med-PaLM released on March 2023 by Google with improved performance | [:link:](https://www.youtube.com/watch?v=3Ud-BMOCkDI&ab_channel=Google) | [:link:](https://arxiv.org/pdf/2305.09617.pdf)  | [:link:](https://repo.com) | [:link:](https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model) |
| PharmacyGPT | In-context Learning | GPT-4 model coupled with in-context learning (dynamic prompting approach) involving domain-specific data | - | [:link:](https://arxiv.org/abs/2307.10432)  | - | - |


<!-- | Name of LLM | Model Type (e.g., Fine-tuned) | Brief info | [:link:](https://demo.com) | [:link:](https://paper.com)  | [:link:](https://repo.com) | [:link:](https://website.com) | | -->